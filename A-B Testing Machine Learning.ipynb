{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "import pandas as pd\r\n",
    "import dvc.api\r\n",
    "import mlflow\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "import seaborn as sns"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "source": [
    "path = 'data\\AdSmartABdata.csv'\r\n",
    "repo = 'https://github.com/SameC137/abtest-mlops'\r\n",
    "rev = 'v2'\r\n",
    "data_url = dvc.api.get_url(path=path, repo=repo,rev=rev)\r\n",
    "\r\n",
    "collected_data = pd.read_csv(data_url,index_col=0)\r\n",
    "collected_data"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                auction_id experiment        date  hour  \\\n",
       "0     0008ef63-77a7-448b-bd1e-075f42c55e39    exposed  2020-07-10     8   \n",
       "1     000eabc5-17ce-4137-8efe-44734d914446    exposed  2020-07-07    10   \n",
       "2     0016d14a-ae18-4a02-a204-6ba53b52f2ed    exposed  2020-07-05     2   \n",
       "3     00187412-2932-4542-a8ef-3633901c98d9    control  2020-07-03    15   \n",
       "4     001a7785-d3fe-4e11-a344-c8735acacc2c    control  2020-07-03    15   \n",
       "...                                    ...        ...         ...   ...   \n",
       "8072  ffea24ec-cec1-43fb-b1d1-8f93828c2be2    exposed  2020-07-05     7   \n",
       "8073  ffea3210-2c3e-426f-a77d-0aa72e73b20f    control  2020-07-03    15   \n",
       "8074  ffeaa0f1-1d72-4ba9-afb4-314b3b00a7c7    control  2020-07-04     9   \n",
       "8075  ffeeed62-3f7c-4a6e-8ba7-95d303d40969    exposed  2020-07-05    15   \n",
       "8076  fffbb9ff-568a-41a5-a0c3-6866592f80d8    control  2020-07-10    14   \n",
       "\n",
       "             device_make  platform_os  yes  no  \n",
       "0     Generic Smartphone            6    0   0  \n",
       "1     Generic Smartphone            6    0   0  \n",
       "2                  E5823            6    0   1  \n",
       "3      Samsung SM-A705FN            6    0   0  \n",
       "4     Generic Smartphone            6    0   0  \n",
       "...                  ...          ...  ...  ..  \n",
       "8072  Generic Smartphone            6    0   0  \n",
       "8073  Generic Smartphone            6    0   0  \n",
       "8074  Generic Smartphone            6    0   0  \n",
       "8075    Samsung SM-A515F            6    0   0  \n",
       "8076    Samsung SM-G960F            6    0   0  \n",
       "\n",
       "[8077 rows x 8 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auction_id</th>\n",
       "      <th>experiment</th>\n",
       "      <th>date</th>\n",
       "      <th>hour</th>\n",
       "      <th>device_make</th>\n",
       "      <th>platform_os</th>\n",
       "      <th>yes</th>\n",
       "      <th>no</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0008ef63-77a7-448b-bd1e-075f42c55e39</td>\n",
       "      <td>exposed</td>\n",
       "      <td>2020-07-10</td>\n",
       "      <td>8</td>\n",
       "      <td>Generic Smartphone</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000eabc5-17ce-4137-8efe-44734d914446</td>\n",
       "      <td>exposed</td>\n",
       "      <td>2020-07-07</td>\n",
       "      <td>10</td>\n",
       "      <td>Generic Smartphone</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0016d14a-ae18-4a02-a204-6ba53b52f2ed</td>\n",
       "      <td>exposed</td>\n",
       "      <td>2020-07-05</td>\n",
       "      <td>2</td>\n",
       "      <td>E5823</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00187412-2932-4542-a8ef-3633901c98d9</td>\n",
       "      <td>control</td>\n",
       "      <td>2020-07-03</td>\n",
       "      <td>15</td>\n",
       "      <td>Samsung SM-A705FN</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001a7785-d3fe-4e11-a344-c8735acacc2c</td>\n",
       "      <td>control</td>\n",
       "      <td>2020-07-03</td>\n",
       "      <td>15</td>\n",
       "      <td>Generic Smartphone</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8072</th>\n",
       "      <td>ffea24ec-cec1-43fb-b1d1-8f93828c2be2</td>\n",
       "      <td>exposed</td>\n",
       "      <td>2020-07-05</td>\n",
       "      <td>7</td>\n",
       "      <td>Generic Smartphone</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8073</th>\n",
       "      <td>ffea3210-2c3e-426f-a77d-0aa72e73b20f</td>\n",
       "      <td>control</td>\n",
       "      <td>2020-07-03</td>\n",
       "      <td>15</td>\n",
       "      <td>Generic Smartphone</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8074</th>\n",
       "      <td>ffeaa0f1-1d72-4ba9-afb4-314b3b00a7c7</td>\n",
       "      <td>control</td>\n",
       "      <td>2020-07-04</td>\n",
       "      <td>9</td>\n",
       "      <td>Generic Smartphone</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8075</th>\n",
       "      <td>ffeeed62-3f7c-4a6e-8ba7-95d303d40969</td>\n",
       "      <td>exposed</td>\n",
       "      <td>2020-07-05</td>\n",
       "      <td>15</td>\n",
       "      <td>Samsung SM-A515F</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8076</th>\n",
       "      <td>fffbb9ff-568a-41a5-a0c3-6866592f80d8</td>\n",
       "      <td>control</td>\n",
       "      <td>2020-07-10</td>\n",
       "      <td>14</td>\n",
       "      <td>Samsung SM-G960F</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8077 rows Ã— 8 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 71
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Select only users with a response"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "source": [
    "responded=collected_data.loc[(collected_data[\"yes\"]==1) | (collected_data[\"no\"]==1)]\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Remove auction Id"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "source": [
    "features= responded.drop([\"auction_id\",\"no\"],axis=1, inplace=False)\r\n",
    "features=features.reset_index(drop=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "source": [
    "y=features[\"yes\"]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "source": [
    "\r\n",
    "\r\n",
    "# lb = LabelEncoder() \r\n",
    "\r\n",
    "# features[\"experiment\"]=lb.fit_transform(features[\"experiment\"])\r\n",
    "\r\n",
    "# features[\"device_make\"]=lb.fit_transform(features[\"device_make\"])\r\n",
    "\r\n",
    "# features[\"browser\"]=lb.fit_transform(features[\"browser\"])\r\n",
    "\r\n",
    "# features[\"date\"]=lb.fit_transform(features[\"date\"])\r\n",
    "\r\n",
    "# features.drop(\"yes\",axis=1,inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "source": [
    "from sklearn.preprocessing import LabelEncoder\r\n",
    "from sklearn.preprocessing import MinMaxScaler\r\n",
    "\r\n",
    "\r\n",
    "def encode_scale_features(df,columns):\r\n",
    "    lb=LabelEncoder()\r\n",
    "    norm = MinMaxScaler()\r\n",
    "    for i in columns:\r\n",
    "        df[i]=lb.fit_transform(df[i])   \r\n",
    "    norm_fit = norm.fit_transform(df)\r\n",
    "    out=pd.DataFrame(norm_fit,columns=df.columns)\r\n",
    "    return out"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "source": [
    "if rev==\"v2\":\r\n",
    "    feat=[\"experiment\",\"device_make\",\"date\"]\r\n",
    "elif rev==\"v3\":\r\n",
    "    feat=[\"experiment\",\"device_make\",\"browser\",\"date\"]\r\n",
    "else:\r\n",
    "    feat=[\"experiment\",\"device_make\",\"browser\",\"plaform_os\",\"date\"]\r\n",
    "\r\n",
    "features=encode_scale_features(features,feat)\r\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "source": [
    "\r\n",
    "\r\n",
    "# creating scaler scale var.\r\n",
    "# norm = MinMaxScaler()\r\n",
    "# fit the scal\r\n",
    "# norm_fit = norm.fit_transform(features)\r\n",
    "\r\n",
    "# X=pd.DataFrame(norm_fit,columns=features.columns)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "source": [
    "from sklearn.model_selection import train_test_split\r\n",
    "\r\n",
    "\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(\r\n",
    "   X, y, test_size=0.3, random_state=1)\r\n",
    "X_train, X_val, y_train, y_val = train_test_split(\r\n",
    "    X_train, y_train, test_size=0.33, random_state=1)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# from sklearn.linear_model import LogisticRegression\r\n",
    "# from sklearn.metrics import mean_squared_error, accuracy_score,log_loss\r\n",
    "# import mlflow\r\n",
    "# import mlflow.sklearn\r\n",
    "\r\n",
    "\r\n",
    "# from mlflow.models.signature import infer_signature\r\n",
    "# from mlflow.utils.environment import _mlflow_conda_env\r\n",
    "\r\n",
    "\r\n",
    "# model = LogisticRegression()\r\n",
    "# with mlflow.start_run() as run:\r\n",
    "#     model.fit(X_train y_train)\r\n",
    "#     pred = cls.predict(X_test)\r\n",
    "#     mlflow.log_metric(f\"accuracy\", kfold_scores.mean())\r\n",
    "#     mlflow.log_metric(f\"std_accuracy\", kfold_scores.std())\r\n",
    "#     print(mean_squared_error(y_test, pred))\r\n",
    "#     print(\"Logged data and model in run {}\".format(run.info.run_id))\r\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# def eval_metrics(actual, pred):\r\n",
    "#     rmse = np.sqrt(mean_squared_error(actual, pred))\r\n",
    "#     mae = mean_absolute_error(actual, pred)\r\n",
    "#     r2 = r2_score(actual, pred)\r\n",
    "#     return rmse, mae, r2\r\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "source": [
    "from sklearn.linear_model import LogisticRegression\r\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, log_loss\r\n",
    "import mlflow\r\n",
    "import mlflow.sklearn\r\n",
    "\r\n",
    "from urllib.parse import urlparse\r\n",
    "\r\n",
    "from mlflow.models.signature import infer_signature\r\n",
    "from mlflow.utils.environment import _mlflow_conda_env\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "\r\n",
    "with mlflow.start_run(run_name='untuned_linear_regression'):\r\n",
    "    \r\n",
    "    mlflow.log_param('data_version', rev)\r\n",
    "    feature_cols=pd.DataFrame(list(X_train.columns))\r\n",
    "    feature_cols.to_csv('features.csv',header=False,index=False)\r\n",
    "    mlflow.log_artifact(\"features.csv\")\r\n",
    "\r\n",
    "    model = LogisticRegression()\r\n",
    "    model.fit(X_train, y_train)\r\n",
    "    \r\n",
    "    pred = model.predict(X_val)\r\n",
    "    rmse = np.sqrt(mean_squared_error(y_val, pred))\r\n",
    "    loss=log_loss(y_val,pred)\r\n",
    "    acc = accuracy_score(y_val, pred)\r\n",
    "\r\n",
    "    \r\n",
    "    mlflow.log_metric(\"rmse\", rmse)\r\n",
    "    mlflow.log_metric(\"log_loss\", loss)\r\n",
    "    \r\n",
    "    mlflow.log_metric(\"accuracy\", acc)\r\n",
    "    \r\n",
    "    tracking_url_type_store = urlparse(mlflow.get_tracking_uri()).scheme\r\n",
    "    if tracking_url_type_store != \"file\":\r\n",
    "        mlflow.sklearn.\r\n",
    "        (model, \"model\", registered_model_name=\"LinearRegressionModel\")\r\n",
    "    else:\r\n",
    "        mlflow.sklearn.log_model(model, \"model\")\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "source": [
    "\r\n",
    "feature_importances = pd.DataFrame((model.coef_).transpose() , index=X_train.columns.tolist(), columns=['importance'])\r\n",
    "feature_importances.sort_values('importance', ascending=False)\r\n",
    "# X_train.columns.tolist()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "             importance\n",
       "device_make    0.364569\n",
       "experiment     0.154695\n",
       "hour          -0.003770\n",
       "browser       -0.062687\n",
       "date          -0.063641"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>device_make</th>\n",
       "      <td>0.364569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experiment</th>\n",
       "      <td>0.154695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hour</th>\n",
       "      <td>-0.003770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>browser</th>\n",
       "      <td>-0.062687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <td>-0.063641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 67
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "source": [
    "from xgboost import XGBClassifier\r\n",
    "\r\n",
    "\r\n",
    "with mlflow.start_run(run_name='untuned_kgboost'):\r\n",
    "    \r\n",
    "    mlflow.log_param('data_version', rev)\r\n",
    "    feature_cols=pd.DataFrame(list(X_train.columns))\r\n",
    "    feature_cols.to_csv('features.csv',header=False,index=False)\r\n",
    "    mlflow.log_artifact(\"features.csv\")\r\n",
    "\r\n",
    "    model = XGBClassifier()\r\n",
    "    model.fit(X_train, y_train)\r\n",
    "    \r\n",
    "    pred = model.predict(X_val)\r\n",
    "    rmse = np.sqrt(mean_squared_error(y_val, pred))\r\n",
    "    loss=log_loss(y_val,pred)\r\n",
    "    acc = accuracy_score(y_val, pred)\r\n",
    "\r\n",
    "    \r\n",
    "    mlflow.log_metric(\"rmse\", rmse)\r\n",
    "    mlflow.log_metric(\"log_loss\", loss)\r\n",
    "    \r\n",
    "    mlflow.log_metric(\"accuracy\", acc)\r\n",
    "    \r\n",
    "    tracking_url_type_store = urlparse(mlflow.get_tracking_uri()).scheme\r\n",
    "    if tracking_url_type_store != \"file\":\r\n",
    "        mlflow.sklearn.log_model(model, \"model\", registered_model_name=\"XGBoost\")\r\n",
    "    else:\r\n",
    "        mlflow.sklearn.log_model(model, \"model\")\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "D:\\Users\\same\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[05:54:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "source": [
    "\r\n",
    "from sklearn.tree import DecisionTreeClassifier\r\n",
    "\r\n",
    "\r\n",
    "with mlflow.start_run(run_name='untuned_decisiontree'):\r\n",
    "    \r\n",
    "    mlflow.log_param('data_version', rev)\r\n",
    "    feature_cols=pd.DataFrame(list(X_train.columns))\r\n",
    "    feature_cols.to_csv('features.csv',header=False,index=False)\r\n",
    "    mlflow.log_artifact(\"features.csv\")\r\n",
    "\r\n",
    "    model = DecisionTreeClassifier()\r\n",
    "    model.fit(X_train, y_train)\r\n",
    "    \r\n",
    "    pred = model.predict(X_val)\r\n",
    "    rmse = np.sqrt(mean_squared_error(y_val, pred))\r\n",
    "    loss=log_loss(y_val,pred)\r\n",
    "    acc = accuracy_score(y_val, pred)\r\n",
    "\r\n",
    "    \r\n",
    "    mlflow.log_metric(\"rmse\", rmse)\r\n",
    "    mlflow.log_metric(\"log_loss\", loss)\r\n",
    "    \r\n",
    "    mlflow.log_metric(\"accuracy\", acc)\r\n",
    "    \r\n",
    "    tracking_url_type_store = urlparse(mlflow.get_tracking_uri()).scheme\r\n",
    "    if tracking_url_type_store != \"file\":\r\n",
    "        mlflow.sklearn.log_model(model, \"model\", registered_model_name=\"DecisionTreeClassifier\")\r\n",
    "    else:\r\n",
    "        mlflow.sklearn.log_model(model, \"model\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "source": [
    "feature_importances = pd.DataFrame((model.feature_importances_).transpose() , index=X_train.columns.tolist(), columns=['importance'])\r\n",
    "feature_importances.sort_values('importance', ascending=False)\r\n",
    "# X_train.columns.tolist()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "             importance\n",
       "hour           0.345331\n",
       "device_make    0.237050\n",
       "date           0.211202\n",
       "experiment     0.106343\n",
       "browser        0.100074"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>hour</th>\n",
       "      <td>0.345331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>device_make</th>\n",
       "      <td>0.237050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <td>0.211202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experiment</th>\n",
       "      <td>0.106343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>browser</th>\n",
       "      <td>0.100074</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 87
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "source": [
    "class CreateModel:\r\n",
    "    def __init__(self, X_train, X_test, y_train, y_test,data_version,name,model):\r\n",
    "        self.X_train = X_train\r\n",
    "        self.X_test = X_test\r\n",
    "        self.y_train = y_train\r\n",
    "        self.y_test = y_test\r\n",
    "        \r\n",
    "        self.model=NULL\r\n",
    "        self.featureImportance=[]\r\n",
    "        self.name=name\r\n",
    "        self.data_version=data_version\r\n",
    "    def train(self,params):\r\n",
    "        with mlflow.start_run(run_name=self.name):\r\n",
    "            mlflow.log_param('data_version', this.data_version)\r\n",
    "            feature_cols=pd.DataFrame(list(self.X_train.columns))\r\n",
    "            feature_cols.to_csv('features.csv',header=False,index=False)\r\n",
    "            mlflow.log_artifact(\"features.csv\")\r\n",
    "\r\n",
    "            model = self.model(**params)\r\n",
    "            model.fit(self.X_train, self.y_train)\r\n",
    "\r\n",
    "            pred = model.predict(self.X_test)\r\n",
    "            rmse = np.sqrt(mean_squared_error(self.y_test, pred))\r\n",
    "            loss=log_loss(self.y_test,pred)\r\n",
    "            acc = accuracy_score(self.y_test, pred)\r\n",
    "\r\n",
    "\r\n",
    "            mlflow.log_metric(\"rmse\", rmse)\r\n",
    "            mlflow.log_metric(\"log_loss\", loss)\r\n",
    "\r\n",
    "            mlflow.log_metric(\"accuracy\", acc)\r\n",
    "\r\n",
    "            tracking_url_type_store = urlparse(mlflow.get_tracking_uri()).scheme\r\n",
    "            if tracking_url_type_store != \"file\":\r\n",
    "                mlflow.sklearn.log_model(model, \"model\", registered_model_name=self.name)\r\n",
    "            else:\r\n",
    "                mlflow.sklearn.log_model(model, \"model\")\r\n",
    "    def trainKFold(self,folds,params):\r\n",
    "        with mlflow.start_run(run_name=self.name):\r\n",
    "            mlflow.log_param('data_version', this.data_version)\r\n",
    "            feature_cols=pd.DataFrame(list(self.X_train.columns))\r\n",
    "            feature_cols.to_csv('features.csv',header=False,index=False)\r\n",
    "            mlflow.log_artifact(\"features.csv\")\r\n",
    "            \r\n",
    "            kf=KFold(n_splits=folds, random_state=None)\r\n",
    "            model = self.model(**params)\r\n",
    "            model.fit(self.X_train, self.y_train)\r\n",
    "\r\n",
    "            pred = model.predict(self.X_test)\r\n",
    "            rmse = np.sqrt(mean_squared_error(self.y_test, pred))\r\n",
    "            loss=log_loss(self.y_test,pred)\r\n",
    "            acc = accuracy_score(self.y_test, pred)\r\n",
    "\r\n",
    "            mlflow.log_metric(\"rmse\", rmse)\r\n",
    "            mlflow.log_metric(\"log_loss\", loss)\r\n",
    "\r\n",
    "            mlflow.log_metric(\"accuracy\", acc)\r\n",
    "\r\n",
    "            tracking_url_type_store = urlparse(mlflow.get_tracking_uri()).scheme\r\n",
    "            if tracking_url_type_store != \"file\":\r\n",
    "                mlflow.sklearn.log_model(model, \"model\", registered_model_name=self.name)\r\n",
    "            else:\r\n",
    "                mlflow.sklearn.log_model(model, \"model\")\r\n",
    "    \r\n",
    "    def getFeatureImportance(self):\r\n",
    "        feature_importances = pd.DataFrame((self.model.feature_importances_).transpose() , index=self.X_train.columns.tolist(), columns=['importance'])\r\n",
    "        return feature_importances.sort_values('importance', ascending=False)"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-88-e5323cbb8e77>, line 1)",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-88-e5323cbb8e77>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    Class CreateModel:\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "source": [
    "X_Cross, X_test, y_Cross, y_test = train_test_split(\r\n",
    "   X, y, test_size=0.1, random_state=1)\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "source": [
    "\r\n",
    "from sklearn.tree import DecisionTreeClassifier\r\n",
    "\r\n",
    "from sklearn.model_selection import cross_val_score\r\n",
    "from sklearn.model_selection import KFold\r\n",
    "\r\n",
    "with mlflow.start_run(run_name='kfold_decisiontree'):\r\n",
    "    \r\n",
    "    mlflow.log_param('data_version', rev)\r\n",
    "    feature_cols=pd.DataFrame(list(X_Cross.columns))\r\n",
    "    feature_cols.to_csv('features.csv',header=False,index=False)\r\n",
    "    mlflow.log_artifact(\"features.csv\")\r\n",
    "    \r\n",
    "    kf = KFold(n_splits=5)\r\n",
    "\r\n",
    "    model = DecisionTreeClassifier()\r\n",
    "    scores=[]\r\n",
    "    for train_index, test_index in kf.split(X_Cross):\r\n",
    "        X_train, X_val, y_train, y_val = X_Cross.iloc[train_index], X_Cross.iloc[test_index], y_Cross.iloc[train_index], y_Cross.iloc[test_index]\r\n",
    "        model.fit(X_train, y_train)\r\n",
    "        predict_valid=model.predict(X_val)\r\n",
    "        valid_loss=log_loss(y_val,predict_valid)\r\n",
    "        scores.append(valid_loss)\r\n",
    "    print(scores)\r\n",
    "    \r\n",
    "    mlflow.log_metric(\"avergae_validation_log_loss\",np.mean( scores))\r\n",
    "    # model.fit(X_train, y_train)\r\n",
    "    \r\n",
    "\r\n",
    "    pred = model.predict(X_test)\r\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, pred))\r\n",
    "    loss=log_loss(y_test,pred)\r\n",
    "    acc = accuracy_score(y_test, pred)\r\n",
    "\r\n",
    "\r\n",
    "    mlflow.log_metric(\"rmse\", rmse)\r\n",
    "    mlflow.log_metric(\"log_loss\", loss)\r\n",
    "    \r\n",
    "    mlflow.log_metric(\"accuracy\", acc)\r\n",
    "    \r\n",
    "    tracking_url_type_store = urlparse(mlflow.get_tracking_uri()).scheme\r\n",
    "    if tracking_url_type_store != \"file\":\r\n",
    "        mlflow.sklearn.log_model(model, \"model\", registered_model_name=\"KfoldDecisionTreeClassifier\")\r\n",
    "    else:\r\n",
    "        mlflow.sklearn.log_model(model, \"model\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[17.423754075441902, 17.269548830867656, 14.648259572462996, 15.798130843905588, 16.262871286586833]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "source": [
    "from xgboost import XGBClassifier\r\n",
    "\r\n",
    "\r\n",
    "with mlflow.start_run(run_name='kfold_kgboost'):\r\n",
    "    \r\n",
    "    mlflow.log_param('data_version', rev)\r\n",
    "    feature_cols=pd.DataFrame(list(X_train.columns))\r\n",
    "    feature_cols.to_csv('features.csv',header=False,index=False)\r\n",
    "    mlflow.log_artifact(\"features.csv\")\r\n",
    "\r\n",
    "    kf = KFold(n_splits=5)\r\n",
    "\r\n",
    "    model = XGBClassifier(use_label_encoder=False)\r\n",
    "    scores=[]\r\n",
    "    for train_index, test_index in kf.split(X_Cross):\r\n",
    "        X_train, X_val, y_train, y_val = X_Cross.iloc[train_index], X_Cross.iloc[test_index], y_Cross.iloc[train_index], y_Cross.iloc[test_index]\r\n",
    "        model.fit(X_train, y_train)\r\n",
    "        predict_valid=model.predict(X_val)\r\n",
    "        valid_loss=log_loss(y_val,predict_valid)\r\n",
    "        scores.append(valid_loss)\r\n",
    "    print(scores)\r\n",
    "    \r\n",
    "    mlflow.log_metric(\"avergae_validation_log_loss\",np.mean( scores))\r\n",
    "\r\n",
    "    \r\n",
    "    pred = model.predict(X_test)\r\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, pred))\r\n",
    "    loss=log_loss(y_test,pred)\r\n",
    "    acc = accuracy_score(y_test, pred)\r\n",
    "\r\n",
    "    \r\n",
    "    mlflow.log_metric(\"rmse\", rmse)\r\n",
    "    mlflow.log_metric(\"log_loss\", loss)\r\n",
    "    \r\n",
    "    mlflow.log_metric(\"accuracy\", acc)\r\n",
    "    \r\n",
    "    tracking_url_type_store = urlparse(mlflow.get_tracking_uri()).scheme\r\n",
    "    if tracking_url_type_store != \"file\":\r\n",
    "        mlflow.xgboost.log_model(model, \"model\", registered_model_name=\"KfoldXGBoost\")\r\n",
    "    else:\r\n",
    "        mlflow.xgboost.log_model(model, \"model\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[09:24:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:24:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:24:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:24:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:24:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17.42376478433606, 17.26957381828735, 14.185679535054103, 15.333487213469256, 15.488412646492005]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "source": [
    "from sklearn.linear_model import LogisticRegression\r\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, log_loss\r\n",
    "import mlflow\r\n",
    "import mlflow.sklearn\r\n",
    "\r\n",
    "from urllib.parse import urlparse\r\n",
    "\r\n",
    "from mlflow.models.signature import infer_signature\r\n",
    "from mlflow.utils.environment import _mlflow_conda_env\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "\r\n",
    "with mlflow.start_run(run_name='kfold_linear_regression'):\r\n",
    "    \r\n",
    "    mlflow.log_param('data_version', rev)\r\n",
    "    feature_cols=pd.DataFrame(list(X_train.columns))\r\n",
    "    feature_cols.to_csv('features.csv',header=False,index=False)\r\n",
    "    mlflow.log_artifact(\"features.csv\")\r\n",
    "\r\n",
    "    kf = KFold(n_splits=5)\r\n",
    "\r\n",
    "    model = LogisticRegression()\r\n",
    "    scores=[]\r\n",
    "    for train_index, test_index in kf.split(X_Cross):\r\n",
    "        X_train, X_val, y_train, y_val = X_Cross.iloc[train_index], X_Cross.iloc[test_index], y_Cross.iloc[train_index], y_Cross.iloc[test_index]\r\n",
    "        model.fit(X_train, y_train)\r\n",
    "        predict_valid=model.predict(X_val)\r\n",
    "        valid_loss=log_loss(y_val,predict_valid)\r\n",
    "        scores.append(valid_loss)\r\n",
    "    print(scores)\r\n",
    "    \r\n",
    "    mlflow.log_metric(\"avergae_validation_log_loss\",np.mean( scores))\r\n",
    "\r\n",
    "    \r\n",
    "    pred = model.predict(X_test)\r\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, pred))\r\n",
    "    loss=log_loss(y_test,pred)\r\n",
    "    acc = accuracy_score(y_test, pred)\r\n",
    "\r\n",
    "    \r\n",
    "    mlflow.log_metric(\"rmse\", rmse)\r\n",
    "    mlflow.log_metric(\"log_loss\", loss)\r\n",
    "    \r\n",
    "    mlflow.log_metric(\"accuracy\", acc)\r\n",
    "    \r\n",
    "    tracking_url_type_store = urlparse(mlflow.get_tracking_uri()).scheme\r\n",
    "    if tracking_url_type_store != \"file\":\r\n",
    "        mlflow.sklearn.log_model(model, \"model\", registered_model_name=\"KfoldLinearRegressionModel\")\r\n",
    "    else:\r\n",
    "        mlflow.sklearn.log_model(model, \"model\")\r\n",
    "\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[16.498451215368725, 16.498544025784728, 15.727532081439028, 16.107816770570867, 15.023654275617263]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "source": [
    "import findspark\r\n",
    "findspark.init()\r\n",
    "\r\n",
    "import pyspark\r\n",
    "\r\n",
    "from hyperopt import fmin, tpe, hp, SparkTrials, Trials, STATUS_OK\r\n",
    "from hyperopt.pyll import scope\r\n",
    "from math import exp\r\n",
    "import numpy as np\r\n",
    "import xgboost as xgb\r\n",
    " \r\n",
    "search_space = {\r\n",
    "  'max_depth': scope.int(hp.quniform('max_depth', 4, 100, 1)),\r\n",
    "  'learning_rate': hp.loguniform('learning_rate', -3, 0),\r\n",
    "  'reg_alpha': hp.loguniform('reg_alpha', -5, -1),\r\n",
    "  'reg_lambda': hp.loguniform('reg_lambda', -6, -1),\r\n",
    "  'min_child_weight': hp.loguniform('min_child_weight', -1, 3),\r\n",
    "  'objective': 'binary:logistic',\r\n",
    "  'seed': 123, # Set a seed for deterministic training\r\n",
    "}\r\n",
    " \r\n",
    "def train_model(params):\r\n",
    "  # With MLflow autologging, hyperparameters and the trained model are automatically logged to MLflow.\r\n",
    "  mlflow.xgboost.autolog()\r\n",
    "  with mlflow.start_run(nested=True):\r\n",
    "    train = xgb.DMatrix(data=X_train, label=y_train)\r\n",
    "    test = xgb.DMatrix(data=X_test, label=y_test)\r\n",
    "    # Pass in the test set so xgb can track an evaluation metric. XGBoost terminates training when the evaluation metric\r\n",
    "    # is no longer improving.\r\n",
    "    booster = xgb.train(params=params, dtrain=train, num_boost_round=1000,\\\r\n",
    "                        evals=[(test, \"test\")], early_stopping_rounds=50)\r\n",
    "   \r\n",
    "    pred = booster.predict(test)\r\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, pred))\r\n",
    "    loss=log_loss(y_test,pred)\r\n",
    "    acc = accuracy_score(y_test, pred)\r\n",
    "    \r\n",
    "    mlflow.log_metric(\"rmse\", rmse)\r\n",
    "    mlflow.log_metric(\"log_loss\", loss)\r\n",
    "    \r\n",
    "    mlflow.log_metric(\"accuracy\", acc)\r\n",
    "\r\n",
    " \r\n",
    "    signature = infer_signature(X_train, booster.predict(train))\r\n",
    "    mlflow.xgboost.log_model(booster, \"model\", registered_model_name=\"HyperXGBoost\")\r\n",
    "    \r\n",
    "    # Set the loss to log loss so fmin min the loss\r\n",
    "    return {'status': STATUS_OK, 'loss': -1*loss, 'booster': booster.attributes()}\r\n",
    " \r\n",
    "# Greater parallelism will lead to speedups, but a less optimal hyperparameter sweep. \r\n",
    "# A reasonable value for parallelism is the square root of max_evals.\r\n",
    "spark_trials = SparkTrials(parallelism=10)\r\n",
    " \r\n",
    "# Run fmin within an MLflow run context so that each hyperparameter configuration is logged as a child run of a parent\r\n",
    "# run called \"xgboost_models\" .\r\n",
    "with mlflow.start_run(run_name='hyper_xgboost'):\r\n",
    "  best_params = fmin(\r\n",
    "    fn=train_model, \r\n",
    "    space=search_space, \r\n",
    "    algo=tpe.suggest, \r\n",
    "    max_evals=96,\r\n",
    "    trials=spark_trials, \r\n",
    "    rstate=np.random.RandomState(123)\r\n",
    "  )"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Couldn't find Spark, make sure SPARK_HOME env is set or Spark is in an expected location (e.g. from homebrew installation).",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-116-d33a00306fcc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfindspark\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mfindspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\same\\anaconda3\\lib\\site-packages\\findspark.py\u001b[0m in \u001b[0;36minit\u001b[1;34m(spark_home, python_path, edit_rc, edit_profile)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mspark_home\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 129\u001b[1;33m         \u001b[0mspark_home\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    130\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mpython_path\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\same\\anaconda3\\lib\\site-packages\\findspark.py\u001b[0m in \u001b[0;36mfind\u001b[1;34m()\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mspark_home\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m     36\u001b[0m             \u001b[1;34m\"Couldn't find Spark, make sure SPARK_HOME env is set\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m             \u001b[1;34m\" or Spark is in an expected location (e.g. from homebrew installation).\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Couldn't find Spark, make sure SPARK_HOME env is set or Spark is in an expected location (e.g. from homebrew installation)."
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "source": [
    "\r\n",
    "from sklearn.model_selection import GridSearchCV\r\n",
    "\r\n",
    "mlflow.xgboost.autolog()\r\n",
    "\r\n",
    "params = {\r\n",
    "        'min_child_weight': [ 5,6,7,8,9 ,10],\r\n",
    "        'gamma': [ 5,6,7,8,9],\r\n",
    "        'subsample': [1.0, 1.2, 1.3],\r\n",
    "        'colsample_bytree': [ 0.8, 0.9,1.0],\r\n",
    "        'max_depth': [2,3,4]\r\n",
    "        }\r\n",
    "\r\n",
    "model = XGBClassifier(learning_rate=0.1, n_estimators=200, objective='binary:logistic', eval_metric=\"logloss\",\r\n",
    "                    silent=True, nthread=2)\r\n",
    "\r\n",
    "cvFold = KFold(n_splits=5)\r\n",
    "gridSearch = GridSearchCV(estimator=model, param_grid=params, n_jobs=-1,  cv=cvFold, scoring=\"neg_log_loss\")\r\n",
    "with mlflow.start_run(run_name='hyperparam_xgboost') as run:\r\n",
    "        searchResults = gridSearch.fit(X_train, y_train)\r\n",
    "        \r\n",
    "        pred=searchResults.predict(X_test)\r\n",
    "        loss=log_loss(y_test,pred)\r\n",
    "        acc = accuracy_score(y_test, pred)\r\n",
    "\r\n",
    "        mlflow.log_metric(\"rmse\", rmse)\r\n",
    "        mlflow.log_metric(\"log_loss\", loss)\r\n",
    "\r\n",
    "        mlflow.log_metric(\"accuracy\", acc)\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "bestModel = searchResults.best_estimator_\r\n",
    "# print(\"Log Loss: {:.2f}\".format(loss))\r\n",
    "\r\n",
    "# mlflow.xgboost.log_model(bestModel, \"model\", registered_model_name=\"HyperXGBoost\")\r\n",
    "\r\n",
    "\r\n",
    "# tracking_url_type_store = urlparse(mlflow.get_tracking_uri()).scheme\r\n",
    "# if tracking_url_type_store != \"file\":\r\n",
    "#         mlflow.xgboost.log_model(bestModel, \"model\", registered_model_name=\"HyperXGBoost\")\r\n",
    "# else:\r\n",
    "#         mlflow.xgboost.log_model(model, \"model\")\r\n",
    "\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021/07/24 11:59:40 WARNING mlflow.utils: Truncated the value of the key `estimator`. Truncated value: `XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              eval_metric='logloss', gamma=None, gpu_id=None,\n",
      "              importance_type='gain', interaction_constr...`\n",
      "D:\\Users\\same\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [-0.69017269         nan         nan -0.69017269         nan         nan\n",
      " -0.69021544         nan         nan -0.69021544         nan         nan\n",
      " -0.69021544         nan         nan -0.69021544         nan         nan\n",
      " -0.68948511         nan         nan -0.68944185         nan         nan\n",
      " -0.68957847         nan         nan -0.68957847         nan         nan\n",
      " -0.68957847         nan         nan -0.68957847         nan         nan\n",
      " -0.68999959         nan         nan -0.68972647         nan         nan\n",
      " -0.68964839         nan         nan -0.68962378         nan         nan\n",
      " -0.68962378         nan         nan -0.68962378         nan         nan\n",
      " -0.6907612          nan         nan -0.6907612          nan         nan\n",
      " -0.6907612          nan         nan -0.6907612          nan         nan\n",
      " -0.6907612          nan         nan -0.6907612          nan         nan\n",
      " -0.69047353         nan         nan -0.6904401          nan         nan\n",
      " -0.6904401          nan         nan -0.6904401          nan         nan\n",
      " -0.6904401          nan         nan -0.6904401          nan         nan\n",
      " -0.69060677         nan         nan -0.6904401          nan         nan\n",
      " -0.6904401          nan         nan -0.6904401          nan         nan\n",
      " -0.6904401          nan         nan -0.6904401          nan         nan\n",
      " -0.69135584         nan         nan -0.69135584         nan         nan\n",
      " -0.69135584         nan         nan -0.69135584         nan         nan\n",
      " -0.69135584         nan         nan -0.69135584         nan         nan\n",
      " -0.69088079         nan         nan -0.69088079         nan         nan\n",
      " -0.69088079         nan         nan -0.69088079         nan         nan\n",
      " -0.69088079         nan         nan -0.69088079         nan         nan\n",
      " -0.69088079         nan         nan -0.69088079         nan         nan\n",
      " -0.69088079         nan         nan -0.69088079         nan         nan\n",
      " -0.69088079         nan         nan -0.69088079         nan         nan\n",
      " -0.69186954         nan         nan -0.69186954         nan         nan\n",
      " -0.69186954         nan         nan -0.69186954         nan         nan\n",
      " -0.69186954         nan         nan -0.69186954         nan         nan\n",
      " -0.69152898         nan         nan -0.69152898         nan         nan\n",
      " -0.69152898         nan         nan -0.69152898         nan         nan\n",
      " -0.69152898         nan         nan -0.69152898         nan         nan\n",
      " -0.69152898         nan         nan -0.69152898         nan         nan\n",
      " -0.69152898         nan         nan -0.69152898         nan         nan\n",
      " -0.69152898         nan         nan -0.69152898         nan         nan\n",
      " -0.69206128         nan         nan -0.69206128         nan         nan\n",
      " -0.69206128         nan         nan -0.69206128         nan         nan\n",
      " -0.69206128         nan         nan -0.69206128         nan         nan\n",
      " -0.69170977         nan         nan -0.69170977         nan         nan\n",
      " -0.69170977         nan         nan -0.69170977         nan         nan\n",
      " -0.69170977         nan         nan -0.69170977         nan         nan\n",
      " -0.69170977         nan         nan -0.69170977         nan         nan\n",
      " -0.69170977         nan         nan -0.69170977         nan         nan\n",
      " -0.69170977         nan         nan -0.69170977         nan         nan\n",
      " -0.69017269         nan         nan -0.69017269         nan         nan\n",
      " -0.69021544         nan         nan -0.69021544         nan         nan\n",
      " -0.69021544         nan         nan -0.69021544         nan         nan\n",
      " -0.68948511         nan         nan -0.68944185         nan         nan\n",
      " -0.68957847         nan         nan -0.68957847         nan         nan\n",
      " -0.68957847         nan         nan -0.68957847         nan         nan\n",
      " -0.68999959         nan         nan -0.68972647         nan         nan\n",
      " -0.68964839         nan         nan -0.68962378         nan         nan\n",
      " -0.68962378         nan         nan -0.68962378         nan         nan\n",
      " -0.6907612          nan         nan -0.6907612          nan         nan\n",
      " -0.6907612          nan         nan -0.6907612          nan         nan\n",
      " -0.6907612          nan         nan -0.6907612          nan         nan\n",
      " -0.69047353         nan         nan -0.6904401          nan         nan\n",
      " -0.6904401          nan         nan -0.6904401          nan         nan\n",
      " -0.6904401          nan         nan -0.6904401          nan         nan\n",
      " -0.69060677         nan         nan -0.6904401          nan         nan\n",
      " -0.6904401          nan         nan -0.6904401          nan         nan\n",
      " -0.6904401          nan         nan -0.6904401          nan         nan\n",
      " -0.69135584         nan         nan -0.69135584         nan         nan\n",
      " -0.69135584         nan         nan -0.69135584         nan         nan\n",
      " -0.69135584         nan         nan -0.69135584         nan         nan\n",
      " -0.69088079         nan         nan -0.69088079         nan         nan\n",
      " -0.69088079         nan         nan -0.69088079         nan         nan\n",
      " -0.69088079         nan         nan -0.69088079         nan         nan\n",
      " -0.69088079         nan         nan -0.69088079         nan         nan\n",
      " -0.69088079         nan         nan -0.69088079         nan         nan\n",
      " -0.69088079         nan         nan -0.69088079         nan         nan\n",
      " -0.69186954         nan         nan -0.69186954         nan         nan\n",
      " -0.69186954         nan         nan -0.69186954         nan         nan\n",
      " -0.69186954         nan         nan -0.69186954         nan         nan\n",
      " -0.69152898         nan         nan -0.69152898         nan         nan\n",
      " -0.69152898         nan         nan -0.69152898         nan         nan\n",
      " -0.69152898         nan         nan -0.69152898         nan         nan\n",
      " -0.69152898         nan         nan -0.69152898         nan         nan\n",
      " -0.69152898         nan         nan -0.69152898         nan         nan\n",
      " -0.69152898         nan         nan -0.69152898         nan         nan\n",
      " -0.69206128         nan         nan -0.69206128         nan         nan\n",
      " -0.69206128         nan         nan -0.69206128         nan         nan\n",
      " -0.69206128         nan         nan -0.69206128         nan         nan\n",
      " -0.69170977         nan         nan -0.69170977         nan         nan\n",
      " -0.69170977         nan         nan -0.69170977         nan         nan\n",
      " -0.69170977         nan         nan -0.69170977         nan         nan\n",
      " -0.69170977         nan         nan -0.69170977         nan         nan\n",
      " -0.69170977         nan         nan -0.69170977         nan         nan\n",
      " -0.69170977         nan         nan -0.69170977         nan         nan\n",
      " -0.69058751         nan         nan -0.69058751         nan         nan\n",
      " -0.69058751         nan         nan -0.69058751         nan         nan\n",
      " -0.69058751         nan         nan -0.69058751         nan         nan\n",
      " -0.69046751         nan         nan -0.69046751         nan         nan\n",
      " -0.69046751         nan         nan -0.69046751         nan         nan\n",
      " -0.69046751         nan         nan -0.69046751         nan         nan\n",
      " -0.69070354         nan         nan -0.69056891         nan         nan\n",
      " -0.690768           nan         nan -0.69074461         nan         nan\n",
      " -0.69046751         nan         nan -0.69046751         nan         nan\n",
      " -0.69100107         nan         nan -0.69100107         nan         nan\n",
      " -0.69100107         nan         nan -0.69100107         nan         nan\n",
      " -0.69100107         nan         nan -0.69100107         nan         nan\n",
      " -0.69100107         nan         nan -0.69100107         nan         nan\n",
      " -0.69100107         nan         nan -0.69100107         nan         nan\n",
      " -0.69100107         nan         nan -0.69100107         nan         nan\n",
      " -0.69113364         nan         nan -0.690999           nan         nan\n",
      " -0.690999           nan         nan -0.690999           nan         nan\n",
      " -0.69100107         nan         nan -0.69100107         nan         nan\n",
      " -0.69138952         nan         nan -0.69138952         nan         nan\n",
      " -0.69138952         nan         nan -0.69138952         nan         nan\n",
      " -0.69138952         nan         nan -0.69138952         nan         nan\n",
      " -0.69138952         nan         nan -0.69138952         nan         nan\n",
      " -0.69138952         nan         nan -0.69138952         nan         nan\n",
      " -0.69138952         nan         nan -0.69138952         nan         nan\n",
      " -0.69138952         nan         nan -0.69138952         nan         nan\n",
      " -0.69138952         nan         nan -0.69138952         nan         nan\n",
      " -0.69138952         nan         nan -0.69138952         nan         nan\n",
      " -0.69190364         nan         nan -0.69190364         nan         nan\n",
      " -0.69190364         nan         nan -0.69190364         nan         nan\n",
      " -0.69190364         nan         nan -0.69190364         nan         nan\n",
      " -0.69190364         nan         nan -0.69190364         nan         nan\n",
      " -0.69190364         nan         nan -0.69190364         nan         nan\n",
      " -0.69190364         nan         nan -0.69190364         nan         nan\n",
      " -0.69190364         nan         nan -0.69190364         nan         nan\n",
      " -0.69190364         nan         nan -0.69190364         nan         nan\n",
      " -0.69190364         nan         nan -0.69190364         nan         nan\n",
      " -0.69206128         nan         nan -0.69206128         nan         nan\n",
      " -0.69206128         nan         nan -0.69206128         nan         nan\n",
      " -0.69206128         nan         nan -0.69206128         nan         nan\n",
      " -0.69206128         nan         nan -0.69206128         nan         nan\n",
      " -0.69206128         nan         nan -0.69206128         nan         nan\n",
      " -0.69206128         nan         nan -0.69206128         nan         nan\n",
      " -0.69206128         nan         nan -0.69206128         nan         nan\n",
      " -0.69206128         nan         nan -0.69206128         nan         nan\n",
      " -0.69206128         nan         nan -0.69206128         nan         nan]\n",
      "  warnings.warn(\n",
      "D:\\Users\\same\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:01:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021/07/24 12:01:37 INFO mlflow.sklearn.utils: Logging the 5 best runs, 805 runs will be omitted.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "source": [
    "\r\n",
    "mlflow.sklearn.autolog()\r\n",
    "\r\n",
    "params = {\r\n",
    "        'criterion': ['gini','entropy'],\r\n",
    "        'max_depth':[4,5,6,7,8,9,10]\r\n",
    "        }\r\n",
    "\r\n",
    "model = DecisionTreeClassifier()\r\n",
    "\r\n",
    "cvFold = KFold(n_splits=5)\r\n",
    "gridSearch = GridSearchCV(estimator=model, param_grid=params, n_jobs=-1,  cv=cvFold, scoring=\"neg_log_loss\")\r\n",
    "with mlflow.start_run(run_name='hyperparam_decision_tree') as run:\r\n",
    "        searchResults = gridSearch.fit(X_train, y_train)\r\n",
    "        \r\n",
    "        pred=searchResults.predict(X_test)\r\n",
    "        loss=log_loss(y_test,pred)\r\n",
    "        acc = accuracy_score(y_test, pred)\r\n",
    "\r\n",
    "        mlflow.log_metric(\"rmse\", rmse)\r\n",
    "        mlflow.log_metric(\"log_loss\", loss)\r\n",
    "\r\n",
    "        mlflow.log_metric(\"accuracy\", acc)\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "bestModel = searchResults.best_estimator_\r\n",
    "# print(\"Log Loss: {:.2f}\".format(loss))\r\n",
    "\r\n",
    "# mlflow.xgboost.log_model(bestModel, \"model\", registered_model_name=\"HyperXGBoost\")\r\n",
    "\r\n",
    "\r\n",
    "# tracking_url_type_store = urlparse(mlflow.get_tracking_uri()).scheme\r\n",
    "# if tracking_url_type_store != \"file\":\r\n",
    "#         mlflow.xgboost.log_model(bestModel, \"model\", registered_model_name=\"HyperXGBoost\")\r\n",
    "# else:\r\n",
    "#         mlflow.xgboost.log_model(model, \"model\")\r\n",
    "\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021/07/24 12:14:28 INFO mlflow.sklearn.utils: Logging the 5 best runs, 9 runs will be omitted.\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "3ebe1e15dab481e38dbc50cacd21ed8ec6b22a54b0f3cb3b993bb569cf9c8bed"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}